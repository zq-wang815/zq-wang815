# 小文件问题总结
## 程序产生小文件的原因
1. 读取的数据源就是大量的小文件
2. 动态分区插入数据，会产生大量的小文件，从而导致map数量剧增
3. Reduce/Task数量较多，最终落地的文件数量和Reduce/Task的个数是一样的

## 小文件带来的影响
文件的数量决定了MapReduce/Spark中Mapper/Task数量，小文件越多，Mapper/Task的任务越多，每个Mapper/Task都会对应启动一个JVM/线程来运行，每个Mapper/Task执行数据很少、个数多，导致占用资源多，甚至这些任务的初始化可能比执行的时间还要多，严重影响性能。

## 如何解决小文件问题
### 1.distribute by
少用动态分区，如果场景下必须使用时，那么记得在SQL语句最后添加上distribute by
`distribute by（分区1，分区2，… ，ceil(rand()*N)）`

并且设置相关参数
— 在 map only 的任务结束时合并小文件
`set hive.merge.mapfiles = true;`

— 在 MapReduce 的任务结束时合并小文件
`set hive.merge.mapredfiles = true;`

— 作业结束时合并文件的大小 
`set hive.merge.size.per.task = 256000000;`

— 每个Map最大输入大小(这个值决定了合并后文件的数量) 
`set mapred.max.split.size=256000000;`   

— 每个reducer的大小， 默认是1G，输入文件如果是10G，那么就会起10个reducer；
`set hive.exec.reducers.bytes.per.reducer=1073741824;`

### 2.repartition/coalesce
```
INSERT ... SELECT /*+REPARTITION(n)*/ ...
INSERT ... SELECT /*+COALESCE(n)*/ ..
```

Coalesce Hint减少了分区数，它仅合并分区 ，因此最大程度地减少了数据移动，但须注意内存不足容易OOM。

Repartition Hint可以增加或减少分区数量，它执行数据的完全shuffle，并确保数据平均分配。

Repartition增加了一个新的stage，因此它不会影响现有阶段的并行性；相反，coalesce会影响现有阶段的并行性，因为它不会添加新stage。该写法还支持多个插入查询和命名子查询。


*额外补充两者的区别*

coalesce，一般有使用到Spark进行完业务处理后，为了避免小文件问题，对RDD/DataFrame进行分区的缩减，避免写入HDFS有大量的小文件问题，从而给HDFS的NameNode内存造成大的压力，而调用coalesce，实则源码调用的是case class Repartition shuffle参数为false的，默认是不走shuffle的。

假设当前spark作业的提交参数是num-executor 10 ，executor-core 2，那么就会有20个Task同时并行，如果对最后结果DataFrame进行coalesce操作缩减为(10)，最后也就只会生成10个文件，也表示只会运行10个task，就会有大量executor空跑，cpu core空转的情况；
而且coalesce的分区缩减是全在内存里进行处理，如果当前处理的数据量过大，这样很容易就导致程序OOM异常

如果 coalesce 前的分区数小于 后预想得到的分区数，coalesce就不会起作用，也不会进行shuffle，因为父RDD和子RDD是窄依赖
Repartition，常用的情况是：上游数据分区数据分布不均匀，才会对RDD/DataFrame等数据集进行重分区，将数据重新分配均匀，

假设原来有N个分区，现在repartition(M)的参数传为M，
   而 N < M ，则会根据HashPartitioner （key的hashCode % M）进行数据的重新划分
   而 N  远大于 M ，那么还是建议走repartition，这样所有的executor都会运作起来，效率更高，如果还是走coalesce，假定参数是1，那么即使原本申请了10个executor，那么最后执行的也只会有1个executor。
   
   
### 3.使用HAR归档文件
以上方法可以修改后运用于每日定时脚本，对于已经产生小文件的hive表可以使用har归档，而且Hive提供了原生支持：
```
set  hive.archive.enabled=  true ;
set  hive.archive.har.parentdir.settable=  true ;
set  har.partfile.size=256000000;
```

